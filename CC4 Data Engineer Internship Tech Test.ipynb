{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "578e6557-0afc-4ab9-87af-5d04aced96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "a0ff30bc-b33c-4077-a06b-cbc804e2ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_url = \"https://raw.githubusercontent.com/Papagoat/brain-assessment/main/restaurant_data.json\"\n",
    "# !wget {restaurant_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "46628a12-1659-4b08-9487-6e15974fd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the JSON dataset into a pandas dataframe\n",
    "restaurant_url = 'restaurant_data.json'\n",
    "restaurant_df = pd.read_json(restaurant_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "37dbec5c-053c-4c61-adb2-23f0206f2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the country-code excel file\n",
    "excel_file_path = 'Country-Code.xlsx'\n",
    "country_df = pd.read_excel(excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398341a3-6eb4-41b3-a3fa-ac55b192d56d",
   "metadata": {},
   "source": [
    "<h1>The below section contains the code for creating 'restaurant.csv', 'restaurant_events.csv' and the output threshold for qn 3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1239fdc5-4c4f-4c76-a627-c28511f6e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Lower Bound  Upper Bound  frequency\n",
      "Rating Category                                     \n",
      "Excellent                4.5          4.9        435\n",
      "Very Good                4.0          4.4        623\n",
      "Good                     3.5          3.9        143\n",
      "Average                  2.5          3.4         60\n",
      "Poor                     2.2          2.2          1\n"
     ]
    }
   ],
   "source": [
    "#normalise the series data into a pandas dataframe\n",
    "restaurants_data = pd.json_normalize(restaurant_df['restaurants'])\n",
    "\n",
    "# list to store extracted values for each restaurant\n",
    "restaurant = []\n",
    "restaurant_events = []\n",
    "rating_list = []\n",
    "\n",
    "# iterate through each row in the dataframe\n",
    "for index, row in restaurants_data.iterrows():\n",
    "    # index goes from 0 to 78\n",
    "    # each row when using iterrows is a series with 19 dictionaries inside\n",
    "    # another for loop to loop through the 19 dictionaries\n",
    "    for restaurant_dict in row:\n",
    "        if isinstance(restaurant_dict, dict):  # Check if the item is a dictionary\n",
    "            # question requires the following fields\n",
    "            # Restaurant Id\n",
    "            # Restaurant Name\n",
    "            # Country\n",
    "            # City\n",
    "            # User Rating Votes\n",
    "            # User Aggregate Rating (in float)\n",
    "            # Cuisines\n",
    "            # we then use .get to reference the keys and get the respective values\n",
    "            \n",
    "            restaurant_id = restaurant_dict.get('restaurant.R.res_id', None)\n",
    "            restaurant_name = restaurant_dict.get('restaurant.name', None)\n",
    "            country_id = restaurant_dict.get('restaurant.location.country_id', None)\n",
    "            city = restaurant_dict.get('restaurant.location.city', None)\n",
    "            user_rating_votes = restaurant_dict.get('restaurant.user_rating.votes', None)\n",
    "            aggregate_rating = restaurant_dict.get('restaurant.user_rating.aggregate_rating', None)\n",
    "            cuisines = restaurant_dict.get('restaurant.cuisines', None)\n",
    "            rating_text = restaurant_dict.get('restaurant.user_rating.rating_text')\n",
    "\n",
    "            \n",
    "    \n",
    "            #append the .get values as a dictionary to the list called restaurant\n",
    "            restaurant.append({\n",
    "                'Restaurant ID': restaurant_id,\n",
    "                'Restaurant Name': restaurant_name,\n",
    "                'Country ID': country_id,\n",
    "                'City': city,\n",
    "                'User Rating Votes': user_rating_votes,\n",
    "                'User Aggregate Rating': aggregate_rating,\n",
    "                'Cuisines': cuisines\n",
    "            })\n",
    "            \n",
    "            #extract the events for this restaurant, if any - this is for qn2\n",
    "            events = restaurant_dict.get('restaurant.zomato_events', [])\n",
    "            for event in events:\n",
    "                event_data = event.get('event', {})\n",
    "                event_start_date = pd.to_datetime(event_data.get('start_date', None), errors='coerce')\n",
    "                event_end_date = pd.to_datetime(event_data.get('end_date', None), errors='coerce')\n",
    "                \n",
    "                # extracting photo_url\n",
    "                photos_list = event_data.get('photos','NA')\n",
    "                photo_url = photos_list[0]['photo'].get('url', 'NA') if photos_list else 'NA'\n",
    "        \n",
    "                #filter for events that took place in April 2019\n",
    "                #event must have both start and end date\n",
    "                if event_start_date and event_end_date and ((event_start_date <= april_end) and (event_end_date >= april_start)): \n",
    "                    restaurant_events.append({\n",
    "                    'Event Id': event_data.get('event_id', 'NA'),\n",
    "                    'Restaurant Id': restaurant_dict.get('restaurant.R.res_id', 'NA'),\n",
    "                    'Restaurant Name': restaurant_dict.get('restaurant.name', 'NA'),\n",
    "                    'Photo URL': photo_url,\n",
    "                    'Event Title': event_data.get('title', 'NA'),\n",
    "                    'Event Start Date': event_start_date if event_start_date else 'NA',\n",
    "                    'Event End Date': event_end_date if event_end_date else 'NA'\n",
    "                    })\n",
    "                    \n",
    "            #append the .get values as a dictionary to the list called rating_list  \n",
    "            if rating_text in (\"Excellent\", \"Very Good\", \"Good\", \"Average\", \"Poor\") and country_id != 17:\n",
    "                rating_list.append({\n",
    "                    'Rating Score': aggregate_rating,\n",
    "                    'Rating Category': rating_text\n",
    "                })\n",
    "\n",
    "#------------------- Qn1 csv -----------------\n",
    "# Convert the extracted list of dictionaries into a dataframe\n",
    "retaurant_df = pd.DataFrame(restaurant)\n",
    "# now we need to join on country id and select country name to get the required field\n",
    "merged_df = pd.merge(retaurant_df, country_df, left_on='Country ID', right_on='Country Code')\n",
    "#using an inner join to remove non matching columns. In the process, we removed rows with the Country ID 17 and City = \"dummy\" in total there were 20 such observations\n",
    "#select the relevant columns\n",
    "final_df = merged_df[['Restaurant ID', 'Restaurant Name', 'Country','City', 'User Rating Votes', 'User Aggregate Rating', 'Cuisines']]\n",
    "final_df.to_csv('restaurants.csv', index=False)\n",
    "\n",
    "\n",
    "#------------------- Qn2 csv -----------------\n",
    "events_df = pd.DataFrame(restaurant_events)\n",
    "events_df.fillna(\"NA\", inplace=True)\n",
    "events_df.to_csv('restaurant_events.csv', index=False)\n",
    "\n",
    "\n",
    "#------------------- Qn3 output -----------------\n",
    "ratings_df = pd.DataFrame(rating_list)\n",
    "ratings_df['Rating Score'] = ratings_df['Rating Score'].astype(float)\n",
    "thresholds = ratings_df.groupby('Rating Category')['Rating Score'].agg(['min', 'max', 'size'])\n",
    "thresholds.rename(columns={'size': 'frequency', 'min': \"Lower Bound\", 'max': \"Upper Bound\"}, inplace=True)\n",
    "thresholds_sorted = thresholds.sort_values('Upper Bound', ascending=False)\n",
    "print(thresholds_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
